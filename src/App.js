import './App.css';
import React, { useState, useEffect } from 'react';
import { OpenAIClient } from '@azure/openai';
import { AzureKeyCredential } from '@azure/openai';
import packagejson from '../package.json';


function App() {

  const [lastPrompt, setLastPrompt] = useState('')
  const [responseData, setResponseData] = useState(null);

  async function sendChatGptRequest(prompt) {

    const client = new OpenAIClient(process.env.REACT_APP_AZURE_OPENAI_ENDPOINT, new AzureKeyCredential(process.env.REACT_APP_AZURE_OPENAI_KEY));
    const deploymentId = "gpt35";
    const messages = [
      { role: "system", content: "You are a helpful assistant. You get prompts which get generated by speech input through a microphone." },
      { role: "user", content: prompt }
    ]
    const result = await client.getChatCompletions(deploymentId, messages);
    const response = result.choices[0].message.content;
    console.log("This is the type: ")
    console.log(typeof response);
    console.log("This is the response!");
    console.log(response);
    setResponseData(response);
    return response;
  }

  


  async function sttFromMic() {

    return new Promise((resolve, reject) => {

      const sdk = require("microsoft-cognitiveservices-speech-sdk");
      const speechConfig = sdk.SpeechConfig.fromSubscription(process.env.REACT_APP_SPEECH_KEY, process.env.REACT_APP_SPEECH_REGION);
      speechConfig.speechRecognitionLanguage = 'en-US';

      const audioConfig = sdk.AudioConfig.fromDefaultMicrophoneInput();
      const recognizer = new sdk.SpeechRecognizer(speechConfig, audioConfig);

      setResponseData('speak into your microphone...')

      recognizer.recognizeOnceAsync(result => {
        if (result.reason === sdk.ResultReason.RecognizedSpeech) {
          console.log(`RECOGNIZED PROMPT: Text=${result.text}`)
          setLastPrompt(result.text);
          resolve(result.text);
        } else {
          const errorMessage = 'ERROR: Speech was cancelled or could not be recognized. Ensure your microphone is working properly.';
          setLastPrompt(errorMessage);
          textToSpeech(errorMessage);
          resolve(null);
        }
      });
    });
  }

  const [isPlaying, setIsPlaying] = useState(false);

  function textToSpeech(textToSpeak) {
    const sdk = require("microsoft-cognitiveservices-speech-sdk");
    const speechConfig = sdk.SpeechConfig.fromSubscription(process.env.REACT_APP_SPEECH_KEY, process.env.REACT_APP_SPEECH_REGION);
    const myPlayer = new sdk.SpeakerAudioDestination();
    myPlayer.onAudioStart = () => {
      setIsPlaying(true);
      console.log("Set started playing right now!");
    }

    myPlayer.onAudioEnd = () => {
      setIsPlaying(false);
      console.log("Set stopped playing right now!");
    }

    const audioConfig = sdk.AudioConfig.fromSpeakerOutput(myPlayer);

    let synthesizer = new sdk.SpeechSynthesizer(speechConfig, audioConfig);

    //const textToSpeak = 'This is an example of speech synthesis for a long passage of text. Pressing the mute button should pause/resume the audio output.';
    console.log(`speaking text: ${textToSpeak}...`);

    synthesizer.speakTextAsync(
      textToSpeak,
      result => {
        let text;
        if (result.reason === sdk.ResultReason.SynthesizingAudioCompleted) {
          text = `synthesis finished for "${textToSpeak}".\n`
        } else if (result.reason === sdk.ResultReason.Canceled) {
          text = `synthesis failed. Error detail: ${result.errorDetails}.\n`
        }
        synthesizer.close();
        synthesizer = undefined;
        console.log(text);
      },
      function (err) {
        console.log(`Error: ${err}.\n`);

        synthesizer.close();
        synthesizer = undefined;
      });

  }

  async function runWorkFlow() {
    //let requestGotSent;

    //The line below got commented out because of no speech input possible (developing in library).
    const generatedPrompt = await sttFromMic();
    //const generatedPrompt = "Give me 3 fun facts."
    if (generatedPrompt) {
      const response = await sendChatGptRequest(generatedPrompt);

      //requestGotSent = true;
      //console.log(requestGotSent);
      //textToSpeech(response);
    } else {
      console.log("No request got sent to ChatGPT");
    }
  }




  return (
    <div className="App">
      <header className="App-header">
        <h1>To create a prompt, press the first button below and start speaking. To hear the response, press the second button.</h1>
        <div>
          <button
            style={{ color: "white", width: "350px", height: "90px", backgroundColor: "#CF3059", border: "2px solid white", boxShadow: "none" }}
            onClick={runWorkFlow}
            disabled={isPlaying}
          >
            Speak in your prompt
          </button>
          <button
            style={{ color: "white", width: "350px", height: "90px", backgroundColor: "#59CF30", border: "2px solid white", boxShadow: "none" }}
            onClick={() => textToSpeech(responseData)}
            disabled={isPlaying}
          >
            Play ChatGPT response
          </button>
        </div>
        {/*<h4 style={{marginTop:"100px"}}>Prompt:</h4>
        <p>{lastPrompt}</p>
        <h4 style={{}}>Answer from ChatGPT:</h4>
        <p>{responseData}</p>*/}
        <p style={{ marginBottom: "0px", position: "absolute", bottom: "10px", right: "10px", fontSize: "12px" }}>Current Version: {packagejson.version}</p>
      </header>
    </div>
  );
}

export default App;
